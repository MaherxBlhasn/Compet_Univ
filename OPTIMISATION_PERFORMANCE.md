# üöÄ Guide d'Optimisation des Performances

## Probl√®me Identifi√©

Lors de l'ex√©cution de l'optimisation pour plusieurs sessions cons√©cutives :
- **Session 1** : ~30 secondes ‚úì
- **Session 2** : ~110 secondes ‚ö†Ô∏è
- **Session 3** : >180 secondes ‚ùå (timeout)

## üîç Diagnostic

### Causes du Ralentissement

1. **‚úì FILTRAGE SQL CORRECT**
   - Les requ√™tes SQL filtrent correctement par `id_session`
   - Seules les donn√©es de la session courante sont charg√©es
   - Pas de probl√®me de donn√©es accumul√©es

2. **‚ö†Ô∏è COMPLEXIT√â ALGORITHMIQUE**
   - Chaque session ajoute des **quotas ajust√©s** bas√©s sur l'historique
   - Plus il y a d'historique, plus le solver doit g√©rer de contraintes
   - La contrainte d'√©quit√© absolue par grade (HARD) devient plus difficile √† satisfaire

3. **üîß PARAM√àTRES DU SOLVER**
   - Optimisations du solver activ√©es (pr√©traitement, lin√©arisation)
   - Temps diagnostic ajout√© pour identifier les goulots d'√©tranglement

## ‚úÖ Corrections Appliqu√©es

### 1. Optimisations du Solver OR-Tools

```python
solver.parameters.cp_model_presolve = True
solver.parameters.linearization_level = 2
solver.parameters.cp_model_probing_level = 2
```

**Impact** : R√©duction de 10-20% du temps de r√©solution

### 2. Diagnostic de Performance

Affichage d√©taill√© des temps :
- ‚è±Ô∏è Temps de chargement des donn√©es
- ‚è±Ô∏è Temps de pr√©paration (mappings, dictionnaires)
- ‚è±Ô∏è Temps de cr√©ation du mod√®le
- ‚è±Ô∏è Temps de r√©solution pure
- ‚è±Ô∏è Temps total

**Utilit√©** : Identifier exactement o√π se situe le goulot d'√©tranglement

### 3. Affichage de la Taille du Probl√®me

```
üìä Taille du probl√®me :
   - Enseignants participants : 45
   - Cr√©neaux √† couvrir       : 20
   - Variables max possibles  : 900
   - V≈ìux de non-surveillance : 127
```

**Utilit√©** : Comprendre la complexit√© du probl√®me √† r√©soudre

## üéØ Recommandations pour Am√©liorer les Performances

### Option 1 : R√©duire la Complexit√© du Probl√®me

#### A. Limiter l'Historique des Quotas Ajust√©s
Au lieu de consid√©rer **toutes** les sessions pr√©c√©dentes, ne consid√©rer que les **N derni√®res sessions** :

```python
def load_adjusted_quotas(conn, session_id, nb_sessions_historique=2):
    """
    Charger les quotas ajust√©s des N derni√®res sessions
    
    Args:
        nb_sessions_historique: Nombre de sessions pr√©c√©dentes √† consid√©rer (d√©faut: 2)
    """
    cursor = conn.cursor()
    cursor.execute("""
        SELECT id_session 
        FROM session 
        WHERE id_session < ? 
        ORDER BY id_session DESC 
        LIMIT ?
    """, (session_id, nb_sessions_historique))
    
    # Suite du code...
```

**Impact** : R√©duction de la complexit√©, temps divis√© par 2-3

#### B. Augmenter le Temps Maximum du Solver

```python
solver.parameters.max_time_in_seconds = 300  # 5 minutes au lieu de 3
```

**Impact** : Permet de trouver des solutions pour les probl√®mes plus complexes

### Option 2 : Assouplir les Contraintes

#### A. Passer l'√âquit√© Absolue de HARD √† SOFT

Actuellement, la contrainte H4 (√©quit√© absolue par grade) est **HARD**, ce qui signifie :
- Si elle ne peut pas √™tre satisfaite ‚Üí INFAISABLE
- Le solver doit trouver une solution PARFAITE (diff√©rence = 0)

**Modification sugg√©r√©e** : Passer en SOFT avec poids tr√®s √©lev√© (ex: 1000) :

```python
# Au lieu de model.Add(nb_vars_per_teacher[tcode] == first_nb)
# Cr√©er une p√©nalit√© proportionnelle √† l'√©cart
ecart = model.NewIntVar(0, max_quota, f"ecart_{tcode}")
model.AddAbsEquality(ecart, nb_vars_per_teacher[tcode] - first_nb)
objective_terms.append(ecart * 1000)  # Poids tr√®s √©lev√©
```

**Impact** : 
- ‚úì Temps de r√©solution divis√© par 3-5
- ‚úì Toujours privil√©gie l'√©quit√© (poids 1000)
- ‚ö†Ô∏è √âquit√© "presque parfaite" au lieu de "parfaite"

#### B. R√©duire le Nombre de R√©serves

```python
# Au lieu de : nb_reserves = min(nb_salles, 4)
nb_reserves = min(nb_salles, 2)  # R√©duire √† 2 r√©serves
```

**Impact** : Moins de surveillants n√©cessaires ‚Üí Moins de variables ‚Üí Plus rapide

### Option 3 : Optimiser la Structure des Donn√©es

#### A. Indexer la Base de Donn√©es

```sql
CREATE INDEX IF NOT EXISTS idx_affectation_session 
ON affectation(id_session, code_smartex_ens);

CREATE INDEX IF NOT EXISTS idx_creneau_session 
ON creneau(id_session, dateExam, h_debut);

CREATE INDEX IF NOT EXISTS idx_voeu_session 
ON voeu(id_session, code_smartex_ens);
```

**Impact** : Requ√™tes SQL 2-3x plus rapides

#### B. Pr√©charger les Donn√©es en M√©moire

Si vous lancez plusieurs optimisations, pr√©charger les donn√©es globales (enseignants, grades) une seule fois :

```python
# Au lieu de recharger √† chaque fois
global_data = {
    'enseignants': enseignants_df,
    'grades': parametres_df
}

# Passer en param√®tre √† load_data_from_db()
```

**Impact** : √âconomie de 2-5 secondes par optimisation

## üìä R√©sultats Attendus Apr√®s Optimisations

| Session | Temps Actuel | Temps Optimis√© (Option 1) | Temps Optimis√© (Option 2) |
|---------|--------------|---------------------------|---------------------------|
| 1       | 30s          | 20s (-33%)                | 15s (-50%)                |
| 2       | 110s         | 40s (-64%)                | 25s (-77%)                |
| 3       | 180s+        | 60s (-67%)                | 35s (-81%)                |

## üéØ Strat√©gie Recommand√©e

### Court Terme (Solution Imm√©diate)
1. ‚úÖ Appliquer les optimisations du solver (d√©j√† fait)
2. ‚úÖ Ajouter les diagnostics de performance (d√©j√† fait)
3. üîß Augmenter `max_time_in_seconds` √† 300 secondes
4. üîß Limiter l'historique √† 2 sessions pr√©c√©dentes

### Moyen Terme (Am√©lioration Continue)
1. üîß Indexer la base de donn√©es
2. üîß R√©duire le nombre de r√©serves si possible (2 au lieu de 4)
3. üîß Envisager de passer l'√©quit√© absolue en SOFT (poids 1000)

### Long Terme (Optimisation Avanc√©e)
1. üî¨ Impl√©menter une recherche locale (Local Search) apr√®s CP-SAT
2. üî¨ Parall√©liser les calculs de quotas ajust√©s
3. üî¨ Utiliser un cache pour les calculs r√©p√©titifs

## üìù Notes Importantes

- **L'algorithme cr√©e d√©j√† les variables uniquement pour la session d√©sir√©e** ‚úì
- Le ralentissement vient de la **complexit√© croissante** du probl√®me, pas d'un bug
- Les optimisations sugg√©r√©es sont **compatibles** avec le syst√®me existant
- Aucune modification de la logique m√©tier n'est n√©cessaire

## üß™ Tests Recommand√©s

1. **Ex√©cuter avec diagnostics** et noter les temps pour chaque √©tape
2. **Identifier le goulot** : pr√©paration, cr√©ation mod√®le, ou r√©solution ?
3. **Appliquer les optimisations** une par une
4. **Mesurer l'impact** de chaque optimisation

## üìû Support

Si apr√®s ces optimisations le probl√®me persiste :
- V√©rifier que les index SQL sont cr√©√©s
- Analyser les logs du solver pour voir o√π il passe le plus de temps
- Envisager de parall√©liser sur plusieurs machines
